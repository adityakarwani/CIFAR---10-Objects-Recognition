{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMk1PTRd+3n569eizMFOzh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityakarwani/CIFAR---10-Objects-Recognition/blob/main/CIFAR_10_Object_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r1jQGRKGCy0",
        "outputId": "30310780-7201-4ef2-9aa3-3b2335aae4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "bOGHgHOYGKO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# daatset api\n",
        "!kaggle competitions download -c cifar-10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHP6xPMTGOWl",
        "outputId": "dbb0b70a-de39-4e5f-80ee-2aec1410a2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oso70deFGXzh",
        "outputId": "89b493b2-3595-4cc6-f918-88e80b0d2d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10.zip  sample_data\t    test.7z  train.7z\n",
            "kaggle.json   sampleSubmission.csv  train    trainLabels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the compessed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/cifar-10.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2k7XloGIFne",
        "outputId": "3b60d1c4-8ade-451b-ae41-f765e7de054b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF0ycuWDIJG-",
        "outputId": "6eaa9985-ec4e-47d3-ad67-509ebb24cf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10.zip  sample_data\t    test.7z  train.7z\n",
            "kaggle.json   sampleSubmission.csv  train    trainLabels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py7zr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1E9tHo9IMYn",
        "outputId": "e5fd5d2f-d25e-478c-aa83-c931d25c858c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.20.0)\n",
            "Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.15.10)\n",
            "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.1.0)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.2)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import py7zr\n",
        "\n",
        "archive = py7zr.SevenZipFile('/content/train.7z', mode='r')\n",
        "archive.extractall()     #archive.extractall(path='/content/Training Data')\n",
        "archive.close()"
      ],
      "metadata": {
        "id": "uwOc6BXFIgQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UOz8uwcIqGg",
        "outputId": "11c9cea5-a0ca-4ded-9f67-11cb54931a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10.zip  sample_data\t    test.7z  train.7z\n",
            "kaggle.json   sampleSubmission.csv  train    trainLabels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "VJjBqqMqJGdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = os.listdir('/content/train')"
      ],
      "metadata": {
        "id": "gcgD7dSGJHF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUmO-eboJQBW",
        "outputId": "55ee9e20-2837-4f0f-a14b-388227535883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVuSVnRzJTxc",
        "outputId": "813a7ca6-dcd9-4ce1-cf06-20bcb3a90358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filenames[0:5])\n",
        "print(filenames[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b1DVMDJJV4O",
        "outputId": "4f42865e-8edf-42f5-f2e3-3da4e62494a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['30044.png', '27890.png', '15791.png', '11585.png', '19968.png']\n",
            "['24002.png', '33265.png', '41508.png', '44423.png', '32575.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv('/content/trainLabels.csv')"
      ],
      "metadata": {
        "id": "BZl03a4zJeYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.shape"
      ],
      "metadata": {
        "id": "V0mRpGeJJku3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e797f4-b6c4-4a22-c1b5-c5ece18ccca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tBIfIgX3nXdW",
        "outputId": "435ccbcc-658e-4810-9a9b-02110a38f4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id       label\n",
              "0   1        frog\n",
              "1   2       truck\n",
              "2   3       truck\n",
              "3   4        deer\n",
              "4   5  automobile"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b54ba484-6e6d-4922-8690-421345cd33d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>frog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>truck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>truck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>deer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>automobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b54ba484-6e6d-4922-8690-421345cd33d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b54ba484-6e6d-4922-8690-421345cd33d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b54ba484-6e6d-4922-8690-421345cd33d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4714967f-bed3-428c-9d6b-8d92ab2401fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4714967f-bed3-428c-9d6b-8d92ab2401fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4714967f-bed3-428c-9d6b-8d92ab2401fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14433,\n        \"min\": 1,\n        \"max\": 50000,\n        \"num_unique_values\": 50000,\n        \"samples\": [\n          33554,\n          9428,\n          200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"dog\",\n          \"truck\",\n          \"horse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df[labels_df['id'] == 7796]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "O15vJrPTnZou",
        "outputId": "9f1609bd-7a89-416b-ae30-6ca3ff3a0f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id label\n",
              "7795  7796  frog"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdfe9e17-f6b9-41bd-be84-cc1536794bce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7795</th>\n",
              "      <td>7796</td>\n",
              "      <td>frog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdfe9e17-f6b9-41bd-be84-cc1536794bce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdfe9e17-f6b9-41bd-be84-cc1536794bce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdfe9e17-f6b9-41bd-be84-cc1536794bce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labels_df[labels_df['id'] == 7796]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7796,\n        \"max\": 7796,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"frog\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixb5x14HneAJ",
        "outputId": "0ff9bae4-8fd1-4469-ce35-d44fa95afc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "frog          5000\n",
              "truck         5000\n",
              "deer          5000\n",
              "automobile    5000\n",
              "bird          5000\n",
              "horse         5000\n",
              "ship          5000\n",
              "cat           5000\n",
              "dog           5000\n",
              "airplane      5000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewGOrcBynvsj",
        "outputId": "65761ab1-6bf0-48c3-d347-3fa492c09e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0              frog\n",
              "1             truck\n",
              "2             truck\n",
              "3              deer\n",
              "4        automobile\n",
              "            ...    \n",
              "49995          bird\n",
              "49996          frog\n",
              "49997         truck\n",
              "49998    automobile\n",
              "49999    automobile\n",
              "Name: label, Length: 50000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dictionary = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
        "\n",
        "labels = [labels_dictionary[i] for i in labels_df['label']]"
      ],
      "metadata": {
        "id": "o8u-Dbd6nxN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_yHv-0Tn1j4",
        "outputId": "9ddc8a9c-a1a6-45ca-9604-2be4075f4d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 9, 9, 4, 1]\n",
            "[2, 6, 9, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('/content/train/49999.png')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "J93Ok86gocuv",
        "outputId": "010cd09a-c2ed-4c16-c3ac-90612913dcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/train/45888.png')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "cMriSpBJo2Lk",
        "outputId": "f0094ffd-de44-46b2-90c1-c445e94e4957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJE0lEQVR4nDVWyY6c13U+59zhr7lY1XM3u1vdbBKULNNUGDHQRFoUDMlAFs7GGwf2xht5YUOv4AdIXsSwDUEQDCSBvGIWjhTZYiQZJJvs6laPVV311/APdzgni5Ie4N57zjde/NWvf8ORq9UKoggLIohwDBGRmq1mYjUhFmXpXPDBA3CMHGMs85III3OlWmNmjvHFmy8mSUJEzOy9V0ox8/HxsXbOVZIkOI8kIkKIkQMCJtYW2SwG7b13LoQowgFAlFIxstZGRKy1zjljzN7eXqVSQURmjjEaY5xz/X7fB6+ttWXpNCGAOOd8WYwnqbEGRIo873QXuwtLpJKlbmfQP8tm43q9nlhLpIqiKMtiMp3evHkzsQkiIgIiishsNkvTNITQbl/R2XTKkQsOeZ4PhyPnytFoWK/XSlcgkDL1+w9efWFnd21t5euvv/74oz9OptN2uxmilN4PBhfbL+xWK9ZaTQRlWWZZkWWZiCil6vW61lqfnZ6AiIjkee59GI2GjUYdCcsyrK9t3rv/4NruzuJCp1lL7t555Uqr9emnfzk5OZhOp5PJZGV5rdvtzOHOsmw2m2VZXqvVkyQBAK01EenRaKiQQoxE5H3Q2mitL/oXa6ubb7x5/+aLN41GhAASEPDG9e3NzY3PP3/04Ye/Y+bV1VVgRsTJdFaW+XQ6bTbazWYzxjh/AADIaKW0CiHkec7MMYbhcKjIvPbaWz+4fdsorCQGQIqiKJ0L3rUalbuv/sPVje0r7TZzFGAWAcQsz+uNRqvdAgAAICIiUkrR6dlpmo4AJEYuitK5klluvHhr59puvWaN1t77WZaNJ9PJbDYezz7/7C8xZvfevt+oN8aTcWQxxo7TtFqpdK90hGOMHlGUIiIEAD0apdksr9WqWmkRAJAQ4ubWZrNZD94pgrKMPkRjLREB0Md/+q/kk//8+S9+qY0unJsrlQhbzVYIwXuPiMYYRBARANJJpRZ8uByNKtZWqzVERMRKYmNwRQ55Nn748OF4kr3+5hs3btywSeXuP7317//2253tnWq1WnrnnAuBm80mAHjvAQARAUBEEFEppf/5J/+y0F0YDC+fP33S2386mYxBdAwhz2co/tH//fX3f/hdmmYnZ6cffPBBYpNr13fefvDeRx99/Ppb90yG3vt6o6K1LstSRLTWSqnvOFCTyZgAod6o7+7uvPvej3/6s3+9dftO5OidG42Gg8uLp48fl4VDhMFFfx4PtUryzjvvlj7++ZP/SIzRSlWs9c7NwSEiAFBKKaX7/f7JySkFV8YYyqLIi7xer7/zox+9fu+t3uHBeDzu9/vPn/dK533wiJhl+dyua6srb77xw9Pj09PT00piOcYQorVWaz23GDMfHR1lWbazs0OJta4oJEYOMQZfFPmdu3eUprOzs+Ewnc4yIiUs3vvZbAoCCKI1bW1tA6i//fVvIQRmVkrNyTPGFEXx7Nlza5Pt7W2ttTZWh+ARQSmOQYzWEuT63rX//eyzIs+K0oUQIsfxeHxxcZFlU6KGUqpatetr6/sHT0MIlQqG4LXW1trxeHxycrKxsbG4uAwASEhEGIKbu0NQXHAx+nqzPsumX371VYixKAoEDCGkaZqO0lAWBLD/7PHJ6dHq8spslhdFIQLGmLOzs2+Oj7a2Nr+9HTGESDFGZg4hzP0tIIGDgKysrlpryrwQEWbOstk3x99cDgZFngnH/af7w9FoYWFhjoxSdHBwkKbp3t5et7swz9QYIwiQiBhrETFGlsgogAzCsr6+TqSyPJsvN5vN/vvhw8PDXp7nrixbzWa93my0ms1m03v/5MkTZr5+/Xqj3hTBGKNzbj4xAQCIzBFiZhRBAObYajY3NtbnqtBGt9utosgfffGFLwsQfu/d99584x6RGo1G+/v7rVZrd3dXa80MzDyPtTnz9N0ukaMPwYcYQwjAQkQv7OyKABEJy2iUjsfjx0/3XemC562trfd/9f61nWtHR0cbGxubm5vfweKzbIaI2hgWEAGNiADinSMiRAwhzL1OpLa2tjY3r/YOewAgEojo5ZdfEqJZmhJIe3nxh+88cMF3Op35WWZ2zhEppbUIiUCMXgNAjKwQRWRe2THGJEmU0tqY+w/e/vCPf4gxLC4uLi0urC0vjsZp2R/Nqol432jUl1dWXFkCQAjBOae1McYKg7Z6Mh3//e9faiICEERiFkSeY2eMMcaywNLy6g9u3z4+OrzzyitL3bbCeH545NKJK93O5XDv1vdjCACQ5/m8/ZVSAGiMPT8/e/bscftKSzOz0po5AkiIRErbSgKIIfgQAoJcudIZXl6cnx13mvWk2YIoH//5k8LzT2q1q9d2QwhFUTjvjTHaWlIakPb39y8vLzY21rqdrp6THL03RpMim1hADMF558uy/OKLR5/+z6c3ru8Q4unpadVUVhYbrXqz/7zXRvv0sDdK0xiCNlobQ6S8D88PngDI3t5etVohUpqZY4iaSAS10hKiDyFGX+RFnpeDwSAdjxJjt69upf3+Ua/XqDZeu/PqrZe/N9Bx9mwfBJMk0cZYayaT6fHxN93ulW63Y1RCpIiIYowAopQ2xgCAc86XriyCcxEAV1ZWjNHTyaxmK7deeqlq7VcHTyfiVasxmmXTLJuXe2IqJydnx8eHy8uLnU4XUSullTKIqOeanTvZe8/MwkKkiRQidjodY8zJyWnv2YHd3lq/ujkMPpJKh2nwvlpNjDWkde+wFzmsra0mNhFmIo0IIhEACRFjCDGGsiyKomCOgCAgSCQC1ibWJOeDy0dPnnzZOxiHYEwyHqfTSao01RvNyNLr9VjC6upyklQUaU1KOJZl5lyJCJqZCWk+OxIpbQRABFhEAKrV6j/effVyMBIOTquo1HA4SEfDTqfT7XSzrBimo06n3W63tU6UMlopkHkhg9YmhKiZGVB86bTWWmlABSKAgMhIhAQbVzeWl9cGF6dLS0vDy8vhoL+6tl6r1c7Pz4uyWFxaarfbSVKx1iqlCImFmdlaq5QeT6Y6Bg7CiCgILMwSv00/RFIKEWxSHVwck1IiMp1Ol5ZX0snk7Oy8Xq8tLi21261KpTr/DypSzBxiUEorpfO8yLLs/wFnB9dQt6dtMQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df[labels_df['id'] == 45888]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "NuXngq0LpBcW",
        "outputId": "abab7cd1-d732-4c96-b56c-2428f2287293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id label\n",
              "45887  45888   dog"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8882691b-a93a-4563-9112-7b407e9a6667\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45887</th>\n",
              "      <td>45888</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8882691b-a93a-4563-9112-7b407e9a6667')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8882691b-a93a-4563-9112-7b407e9a6667 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8882691b-a93a-4563-9112-7b407e9a6667');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labels_df[labels_df['id'] == 45888]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 45888,\n        \"max\": 45888,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          45888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"dog\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_list = list(labels_df['id'])"
      ],
      "metadata": {
        "id": "kBAhg0s-pFzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dakNNIBnpMOs",
        "outputId": "1d10a6e5-a29b-4461-d89c-321de38b73b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999,\n",
              " 1000,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert images to numpy arrays\n",
        "\n",
        "train_data_folder = '/content/train/'\n",
        "\n",
        "data = []\n",
        "\n",
        "for id in id_list:\n",
        "\n",
        "  image = Image.open(train_data_folder + str(id) + '.png')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ],
      "metadata": {
        "id": "s4Z7s4GQpPU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvbmiDqRpXUO",
        "outputId": "b1bd4a2b-6536-47b7-e0e6-4d3e268f382e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S_Joh86pa85",
        "outputId": "6ca0e8f0-e5ad-4843-bac5-d357192cb545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6RLnH-tpcLN",
        "outputId": "fa994755-859a-45d3-e379-9ee6baf9d5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1yeG9LDpe2M",
        "outputId": "f545d6ea-88a7-482b-95db-d109f559ad24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "S9EZeA2QpgBs",
        "outputId": "27d8507c-2717-49ca-e592-8cc089c3df1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-95c04611-79f6-4bf9-9862-b2e106099126\" class=\"ndarray_repr\"><pre>ndarray (32, 32, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-95c04611-79f6-4bf9-9862-b2e106099126 button').onclick = (e) => {\n",
              "        document.querySelector('#id-95c04611-79f6-4bf9-9862-b2e106099126').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-95c04611-79f6-4bf9-9862-b2e106099126 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert image list and label list to numpy arrays\n",
        "\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "MWiBzwflply7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE0NhIkBpokL",
        "outputId": "fee93cd8-5ce4-490b-8272-23eb3aaabaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec5tbxObpp9I",
        "outputId": "941cb34e-f9cd-4526-c5e7-b85a593050cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "1BqQnUgqpq-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape,X_train.shape,X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpDaybU2psXx",
        "outputId": "db9e26a0-0430-4e76-8099-1465d2814fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (40000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "-J29fxHHp1gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mehfwVPjrJV4",
        "outputId": "6f2bb0ce-da2a-4f91-9b93-b411236f6a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.81960784, 0.82352941, 0.79607843],\n",
              "         [0.83529412, 0.83921569, 0.81960784],\n",
              "         [0.85490196, 0.85882353, 0.84313725],\n",
              "         ...,\n",
              "         [0.49803922, 0.29019608, 0.15294118],\n",
              "         [0.47843137, 0.26666667, 0.1372549 ],\n",
              "         [0.45490196, 0.24705882, 0.1254902 ]],\n",
              "\n",
              "        [[0.82352941, 0.82352941, 0.79215686],\n",
              "         [0.83529412, 0.83921569, 0.81176471],\n",
              "         [0.85490196, 0.8627451 , 0.83921569],\n",
              "         ...,\n",
              "         [0.48627451, 0.2745098 , 0.1372549 ],\n",
              "         [0.4745098 , 0.2627451 , 0.12941176],\n",
              "         [0.48235294, 0.27058824, 0.14117647]],\n",
              "\n",
              "        [[0.80784314, 0.80392157, 0.76470588],\n",
              "         [0.81960784, 0.81960784, 0.79215686],\n",
              "         [0.83529412, 0.84313725, 0.81960784],\n",
              "         ...,\n",
              "         [0.48627451, 0.2745098 , 0.14509804],\n",
              "         [0.51372549, 0.30196078, 0.16470588],\n",
              "         [0.51372549, 0.30588235, 0.16078431]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.49803922, 0.42352941, 0.38039216],\n",
              "         [0.54117647, 0.47843137, 0.43137255],\n",
              "         [0.55294118, 0.49803922, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.61960784, 0.58431373, 0.5254902 ],\n",
              "         [0.63137255, 0.61176471, 0.59215686],\n",
              "         [0.53333333, 0.5372549 , 0.58039216]],\n",
              "\n",
              "        [[0.56862745, 0.50980392, 0.46666667],\n",
              "         [0.58039216, 0.52941176, 0.50196078],\n",
              "         [0.53333333, 0.49803922, 0.50196078],\n",
              "         ...,\n",
              "         [0.68627451, 0.68235294, 0.6745098 ],\n",
              "         [0.62745098, 0.63137255, 0.66666667],\n",
              "         [0.56078431, 0.58039216, 0.64313725]],\n",
              "\n",
              "        [[0.54117647, 0.50196078, 0.48235294],\n",
              "         [0.54901961, 0.51764706, 0.53333333],\n",
              "         [0.53333333, 0.51372549, 0.54901961],\n",
              "         ...,\n",
              "         [0.58823529, 0.60392157, 0.6627451 ],\n",
              "         [0.56862745, 0.58431373, 0.65098039],\n",
              "         [0.54901961, 0.56862745, 0.63921569]]],\n",
              "\n",
              "\n",
              "       [[[0.73333333, 0.81176471, 0.94117647],\n",
              "         [0.72941176, 0.80392157, 0.92941176],\n",
              "         [0.7372549 , 0.81176471, 0.94117647],\n",
              "         ...,\n",
              "         [0.64705882, 0.78823529, 0.9254902 ],\n",
              "         [0.63921569, 0.77647059, 0.92156863],\n",
              "         [0.63921569, 0.78039216, 0.9254902 ]],\n",
              "\n",
              "        [[0.75686275, 0.83137255, 0.95294118],\n",
              "         [0.75294118, 0.82352941, 0.94509804],\n",
              "         [0.76078431, 0.83137255, 0.95294118],\n",
              "         ...,\n",
              "         [0.6627451 , 0.8       , 0.93333333],\n",
              "         [0.65490196, 0.79215686, 0.93333333],\n",
              "         [0.65490196, 0.79215686, 0.93333333]],\n",
              "\n",
              "        [[0.77647059, 0.83921569, 0.95686275],\n",
              "         [0.76862745, 0.83137255, 0.94509804],\n",
              "         [0.77647059, 0.83921569, 0.95294118],\n",
              "         ...,\n",
              "         [0.6745098 , 0.80392157, 0.93333333],\n",
              "         [0.66666667, 0.79607843, 0.9254902 ],\n",
              "         [0.66666667, 0.8       , 0.93333333]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.24705882, 0.63529412, 0.67058824],\n",
              "         [0.23921569, 0.62352941, 0.65882353],\n",
              "         [0.25490196, 0.63921569, 0.6745098 ],\n",
              "         ...,\n",
              "         [0.38039216, 0.71372549, 0.71372549],\n",
              "         [0.38039216, 0.70980392, 0.70980392],\n",
              "         [0.38431373, 0.72156863, 0.72156863]],\n",
              "\n",
              "        [[0.22745098, 0.64705882, 0.68235294],\n",
              "         [0.21568627, 0.63137255, 0.6627451 ],\n",
              "         [0.24313725, 0.64705882, 0.67843137],\n",
              "         ...,\n",
              "         [0.37254902, 0.70196078, 0.70196078],\n",
              "         [0.36862745, 0.70196078, 0.69411765],\n",
              "         [0.36862745, 0.70980392, 0.69803922]],\n",
              "\n",
              "        [[0.20392157, 0.64705882, 0.68627451],\n",
              "         [0.21176471, 0.65098039, 0.6745098 ],\n",
              "         [0.25882353, 0.66666667, 0.69019608],\n",
              "         ...,\n",
              "         [0.37254902, 0.68235294, 0.69019608],\n",
              "         [0.36470588, 0.68627451, 0.6745098 ],\n",
              "         [0.36470588, 0.69803922, 0.67058824]]],\n",
              "\n",
              "\n",
              "       [[[0.41568627, 0.4627451 , 0.56078431],\n",
              "         [0.40392157, 0.45098039, 0.54901961],\n",
              "         [0.40784314, 0.45882353, 0.55294118],\n",
              "         ...,\n",
              "         [0.34901961, 0.38039216, 0.49411765],\n",
              "         [0.34509804, 0.36862745, 0.4745098 ],\n",
              "         [0.32941176, 0.34509804, 0.44313725]],\n",
              "\n",
              "        [[0.34901961, 0.38823529, 0.50588235],\n",
              "         [0.34117647, 0.38431373, 0.49803922],\n",
              "         [0.34509804, 0.38823529, 0.50196078],\n",
              "         ...,\n",
              "         [0.28235294, 0.32156863, 0.44705882],\n",
              "         [0.31372549, 0.34509804, 0.4627451 ],\n",
              "         [0.30196078, 0.3254902 , 0.43529412]],\n",
              "\n",
              "        [[0.29803922, 0.37254902, 0.49411765],\n",
              "         [0.29411765, 0.36470588, 0.48627451],\n",
              "         [0.29411765, 0.36470588, 0.48627451],\n",
              "         ...,\n",
              "         [0.22352941, 0.29411765, 0.45490196],\n",
              "         [0.23921569, 0.29803922, 0.45098039],\n",
              "         [0.23529412, 0.29019608, 0.43529412]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.16078431, 0.19607843, 0.31372549],\n",
              "         [0.15294118, 0.18823529, 0.30196078],\n",
              "         [0.14509804, 0.18039216, 0.29411765],\n",
              "         ...,\n",
              "         [0.14509804, 0.18039216, 0.30980392],\n",
              "         [0.14509804, 0.18039216, 0.30980392],\n",
              "         [0.15686275, 0.19215686, 0.32156863]],\n",
              "\n",
              "        [[0.17647059, 0.20784314, 0.31764706],\n",
              "         [0.16470588, 0.19607843, 0.30980392],\n",
              "         [0.16470588, 0.19215686, 0.31372549],\n",
              "         ...,\n",
              "         [0.15294118, 0.18039216, 0.30980392],\n",
              "         [0.15686275, 0.18431373, 0.31764706],\n",
              "         [0.16078431, 0.19215686, 0.32156863]],\n",
              "\n",
              "        [[0.18431373, 0.22745098, 0.33333333],\n",
              "         [0.16078431, 0.20392157, 0.31764706],\n",
              "         [0.16470588, 0.20392157, 0.32941176],\n",
              "         ...,\n",
              "         [0.16078431, 0.18431373, 0.31372549],\n",
              "         [0.16078431, 0.18431373, 0.31764706],\n",
              "         [0.15686275, 0.18039216, 0.31372549]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.79215686, 0.65098039, 0.54117647],\n",
              "         [0.84313725, 0.70196078, 0.59607843],\n",
              "         [0.91764706, 0.77647059, 0.67058824],\n",
              "         ...,\n",
              "         [0.61960784, 0.62745098, 0.61568627],\n",
              "         [0.61568627, 0.62745098, 0.61176471],\n",
              "         [0.64705882, 0.65490196, 0.64313725]],\n",
              "\n",
              "        [[0.81176471, 0.68627451, 0.57254902],\n",
              "         [0.86666667, 0.74117647, 0.63137255],\n",
              "         [0.93333333, 0.81176471, 0.69803922],\n",
              "         ...,\n",
              "         [0.67058824, 0.67843137, 0.66666667],\n",
              "         [0.57254902, 0.58039216, 0.56862745],\n",
              "         [0.53333333, 0.54117647, 0.52941176]],\n",
              "\n",
              "        [[0.84705882, 0.71764706, 0.60392157],\n",
              "         [0.89411765, 0.76862745, 0.65490196],\n",
              "         [0.94117647, 0.81568627, 0.70196078],\n",
              "         ...,\n",
              "         [0.55294118, 0.56078431, 0.54901961],\n",
              "         [0.52156863, 0.52941176, 0.51764706],\n",
              "         [0.57647059, 0.58431373, 0.57254902]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.65882353, 0.67058824, 0.65882353],\n",
              "         [0.58823529, 0.60392157, 0.58431373],\n",
              "         [0.53333333, 0.55294118, 0.5254902 ],\n",
              "         ...,\n",
              "         [0.03137255, 0.0627451 , 0.0745098 ],\n",
              "         [0.10196078, 0.17254902, 0.23137255],\n",
              "         [0.16470588, 0.27058824, 0.36470588]],\n",
              "\n",
              "        [[0.48235294, 0.49411765, 0.49019608],\n",
              "         [0.29019608, 0.31372549, 0.30196078],\n",
              "         [0.32941176, 0.36862745, 0.34117647],\n",
              "         ...,\n",
              "         [0.03137255, 0.0745098 , 0.10196078],\n",
              "         [0.11764706, 0.2       , 0.26666667],\n",
              "         [0.18431373, 0.29411765, 0.39215686]],\n",
              "\n",
              "        [[0.3372549 , 0.34509804, 0.35294118],\n",
              "         [0.14509804, 0.17647059, 0.19215686],\n",
              "         [0.17647059, 0.22352941, 0.24705882],\n",
              "         ...,\n",
              "         [0.05490196, 0.10980392, 0.16862745],\n",
              "         [0.16078431, 0.25098039, 0.34509804],\n",
              "         [0.18823529, 0.29803922, 0.41568627]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 0.99607843, 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [0.99607843, 1.        , 1.        ],\n",
              "         [0.99215686, 1.        , 1.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.88235294, 0.8745098 , 0.88235294],\n",
              "         [0.84313725, 0.84313725, 0.84705882],\n",
              "         [0.75294118, 0.76078431, 0.76470588],\n",
              "         ...,\n",
              "         [0.80392157, 0.84705882, 0.82745098],\n",
              "         [0.81176471, 0.84705882, 0.84313725],\n",
              "         [0.86666667, 0.88627451, 0.89803922]],\n",
              "\n",
              "        [[0.87058824, 0.87058824, 0.8627451 ],\n",
              "         [0.84705882, 0.85098039, 0.84313725],\n",
              "         [0.8       , 0.81568627, 0.80392157],\n",
              "         ...,\n",
              "         [0.81568627, 0.85882353, 0.83921569],\n",
              "         [0.83529412, 0.8745098 , 0.86666667],\n",
              "         [0.88627451, 0.90588235, 0.92156863]],\n",
              "\n",
              "        [[0.8745098 , 0.8745098 , 0.85882353],\n",
              "         [0.86666667, 0.8745098 , 0.85490196],\n",
              "         [0.84705882, 0.8627451 , 0.83921569],\n",
              "         ...,\n",
              "         [0.80784314, 0.84705882, 0.83137255],\n",
              "         [0.83137255, 0.8627451 , 0.85882353],\n",
              "         [0.85882353, 0.87843137, 0.88627451]]],\n",
              "\n",
              "\n",
              "       [[[0.70196078, 0.7254902 , 0.77647059],\n",
              "         [0.68627451, 0.70980392, 0.76078431],\n",
              "         [0.71764706, 0.74117647, 0.78823529],\n",
              "         ...,\n",
              "         [0.75686275, 0.84705882, 0.91372549],\n",
              "         [0.76078431, 0.83137255, 0.89019608],\n",
              "         [0.78823529, 0.83921569, 0.87843137]],\n",
              "\n",
              "        [[0.69411765, 0.74117647, 0.80784314],\n",
              "         [0.69019608, 0.72156863, 0.77647059],\n",
              "         [0.71764706, 0.7372549 , 0.78039216],\n",
              "         ...,\n",
              "         [0.79215686, 0.86666667, 0.92156863],\n",
              "         [0.76862745, 0.83529412, 0.89019608],\n",
              "         [0.76862745, 0.82745098, 0.87058824]],\n",
              "\n",
              "        [[0.67843137, 0.74117647, 0.82745098],\n",
              "         [0.70196078, 0.7372549 , 0.8       ],\n",
              "         [0.70196078, 0.71764706, 0.76078431],\n",
              "         ...,\n",
              "         [0.84705882, 0.90196078, 0.94901961],\n",
              "         [0.8       , 0.85490196, 0.90588235],\n",
              "         [0.77647059, 0.83921569, 0.89019608]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.15294118, 0.17254902, 0.14901961],\n",
              "         [0.17254902, 0.18039216, 0.14117647],\n",
              "         [0.18823529, 0.18823529, 0.14117647],\n",
              "         ...,\n",
              "         [0.04705882, 0.05098039, 0.03137255],\n",
              "         [0.09411765, 0.09019608, 0.07058824],\n",
              "         [0.2       , 0.18823529, 0.17254902]],\n",
              "\n",
              "        [[0.15686275, 0.16862745, 0.14509804],\n",
              "         [0.19215686, 0.19215686, 0.16470588],\n",
              "         [0.24313725, 0.23529412, 0.2       ],\n",
              "         ...,\n",
              "         [0.04705882, 0.05098039, 0.03529412],\n",
              "         [0.05098039, 0.04705882, 0.02745098],\n",
              "         [0.18039216, 0.16078431, 0.13333333]],\n",
              "\n",
              "        [[0.14901961, 0.14901961, 0.12941176],\n",
              "         [0.15686275, 0.1372549 , 0.12156863],\n",
              "         [0.17647059, 0.14901961, 0.13333333],\n",
              "         ...,\n",
              "         [0.05098039, 0.04313725, 0.03921569],\n",
              "         [0.07843137, 0.0627451 , 0.03921569],\n",
              "         [0.16078431, 0.13333333, 0.09019608]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "mhwXKqI4rLWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ba9ddd60-2a4a-43fb-f772-e3bb7ca53e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[209, 210, 203],\n",
              "        [213, 214, 209],\n",
              "        [218, 219, 215],\n",
              "        ...,\n",
              "        [127,  74,  39],\n",
              "        [122,  68,  35],\n",
              "        [116,  63,  32]],\n",
              "\n",
              "       [[210, 210, 202],\n",
              "        [213, 214, 207],\n",
              "        [218, 220, 214],\n",
              "        ...,\n",
              "        [124,  70,  35],\n",
              "        [121,  67,  33],\n",
              "        [123,  69,  36]],\n",
              "\n",
              "       [[206, 205, 195],\n",
              "        [209, 209, 202],\n",
              "        [213, 215, 209],\n",
              "        ...,\n",
              "        [124,  70,  37],\n",
              "        [131,  77,  42],\n",
              "        [131,  78,  41]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[127, 108,  97],\n",
              "        [138, 122, 110],\n",
              "        [141, 127, 118],\n",
              "        ...,\n",
              "        [158, 149, 134],\n",
              "        [161, 156, 151],\n",
              "        [136, 137, 148]],\n",
              "\n",
              "       [[145, 130, 119],\n",
              "        [148, 135, 128],\n",
              "        [136, 127, 128],\n",
              "        ...,\n",
              "        [175, 174, 172],\n",
              "        [160, 161, 170],\n",
              "        [143, 148, 164]],\n",
              "\n",
              "       [[138, 128, 123],\n",
              "        [140, 132, 136],\n",
              "        [136, 131, 140],\n",
              "        ...,\n",
              "        [150, 154, 169],\n",
              "        [145, 149, 166],\n",
              "        [140, 145, 163]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-ed27b4a4-7628-477f-ad94-00a01c9e02aa\" class=\"ndarray_repr\"><pre>ndarray (32, 32, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[209, 210, 203],\n",
              "        [213, 214, 209],\n",
              "        [218, 219, 215],\n",
              "        ...,\n",
              "        [127,  74,  39],\n",
              "        [122,  68,  35],\n",
              "        [116,  63,  32]],\n",
              "\n",
              "       [[210, 210, 202],\n",
              "        [213, 214, 207],\n",
              "        [218, 220, 214],\n",
              "        ...,\n",
              "        [124,  70,  35],\n",
              "        [121,  67,  33],\n",
              "        [123,  69,  36]],\n",
              "\n",
              "       [[206, 205, 195],\n",
              "        [209, 209, 202],\n",
              "        [213, 215, 209],\n",
              "        ...,\n",
              "        [124,  70,  37],\n",
              "        [131,  77,  42],\n",
              "        [131,  78,  41]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[127, 108,  97],\n",
              "        [138, 122, 110],\n",
              "        [141, 127, 118],\n",
              "        ...,\n",
              "        [158, 149, 134],\n",
              "        [161, 156, 151],\n",
              "        [136, 137, 148]],\n",
              "\n",
              "       [[145, 130, 119],\n",
              "        [148, 135, 128],\n",
              "        [136, 127, 128],\n",
              "        ...,\n",
              "        [175, 174, 172],\n",
              "        [160, 161, 170],\n",
              "        [143, 148, 164]],\n",
              "\n",
              "       [[138, 128, 123],\n",
              "        [140, 132, 136],\n",
              "        [136, 131, 140],\n",
              "        ...,\n",
              "        [150, 154, 169],\n",
              "        [145, 149, 166],\n",
              "        [140, 145, 163]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-ed27b4a4-7628-477f-ad94-00a01c9e02aa button').onclick = (e) => {\n",
              "        document.querySelector('#id-ed27b4a4-7628-477f-ad94-00a01c9e02aa').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-ed27b4a4-7628-477f-ad94-00a01c9e02aa button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "HvAYiIOntsmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))  # num_of_classes is 10"
      ],
      "metadata": {
        "id": "w67gkMHrtvyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "fvAkW2ThuSqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the neural network\n",
        "model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA_3DLhLu0dt",
        "outputId": "d097096d-3ab2-416e-8ee2-017029cfd1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1125/1125 [==============================] - 250s 210ms/step - loss: 1.6691 - acc: 0.3991 - val_loss: 1.2405 - val_acc: 0.5527\n",
            "Epoch 2/10\n",
            "1125/1125 [==============================] - 190s 169ms/step - loss: 1.2604 - acc: 0.5601 - val_loss: 1.1242 - val_acc: 0.6168\n",
            "Epoch 3/10\n",
            "1125/1125 [==============================] - 186s 166ms/step - loss: 1.0846 - acc: 0.6286 - val_loss: 0.9575 - val_acc: 0.6620\n",
            "Epoch 4/10\n",
            "1125/1125 [==============================] - 185s 165ms/step - loss: 0.9787 - acc: 0.6691 - val_loss: 0.9131 - val_acc: 0.6873\n",
            "Epoch 5/10\n",
            "1125/1125 [==============================] - 193s 171ms/step - loss: 0.8958 - acc: 0.6967 - val_loss: 0.7997 - val_acc: 0.7100\n",
            "Epoch 6/10\n",
            "1125/1125 [==============================] - 192s 171ms/step - loss: 0.8366 - acc: 0.7161 - val_loss: 0.7545 - val_acc: 0.7385\n",
            "Epoch 7/10\n",
            "1125/1125 [==============================] - 182s 162ms/step - loss: 0.7855 - acc: 0.7316 - val_loss: 0.8236 - val_acc: 0.7140\n",
            "Epoch 8/10\n",
            "1125/1125 [==============================] - 194s 173ms/step - loss: 0.7499 - acc: 0.7489 - val_loss: 0.7854 - val_acc: 0.7295\n",
            "Epoch 9/10\n",
            "1125/1125 [==============================] - 190s 169ms/step - loss: 0.7095 - acc: 0.7616 - val_loss: 0.7152 - val_acc: 0.7530\n",
            "Epoch 10/10\n",
            "1125/1125 [==============================] - 188s 167ms/step - loss: 0.6763 - acc: 0.7707 - val_loss: 0.6786 - val_acc: 0.7595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ba1f60ac850>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential, models, layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "XsJwHIStu2Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convolutional_base = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
        "convolutional_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LljHA_Uyv0-D",
        "outputId": "abdf0a0c-ed6e-4caa-b371-a84debcf7b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 262, 262, 3)          0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 128, 128, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 128, 128, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 128, 128, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 130, 130, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 64, 64, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 64, 64, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 64, 64, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 64, 64, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 64, 64, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 64, 64, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 64, 64, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 64, 64, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 64, 64, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 64, 64, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 64, 64, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 64, 64, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 64, 64, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 64, 64, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 64, 64, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 64, 64, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 64, 64, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 64, 64, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 64, 64, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 64, 64, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 64, 64, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 64, 64, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 64, 64, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 32, 32, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 32, 32, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 32, 32, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 32, 32, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 32, 32, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 32, 32, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 32, 32, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 32, 32, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 32, 32, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 32, 32, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 32, 32, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 32, 32, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 32, 32, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 32, 32, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 32, 32, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 32, 32, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 32, 32, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 32, 32, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 32, 32, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 32, 32, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 32, 32, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 16, 16, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 16, 16, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 16, 16, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 16, 16, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 16, 16, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 16, 16, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 16, 16, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 16, 16, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 16, 16, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 16, 16, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 16, 16, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 16, 16, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 16, 16, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 16, 16, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 16, 16, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 16, 16, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 16, 16, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 16, 16, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 16, 16, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 16, 16, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 16, 16, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 16, 16, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 16, 16, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 16, 16, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 16, 16, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 16, 16, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 16, 16, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 16, 16, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 16, 16, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 16, 16, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 16, 16, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 16, 16, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 8, 8, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 8, 8, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 8, 8, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 8, 8, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 8, 8, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 8, 8, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 8, 8, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 8, 8, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 8, 8, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 8, 8, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 8, 8, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 8, 8, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 8, 8, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 8, 8, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 8, 8, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 8, 8, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 8, 8, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 8, 8, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 8, 8, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 8, 8, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23587712 (89.98 MB)\n",
            "Trainable params: 23534592 (89.78 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 10\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(convolutional_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(num_of_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "qDTID-Fnv1A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2cW_CYJ13sv",
        "outputId": "0066dd5e-8404-436a-f39e-c4b9eac9f9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "6OarlfXIv1Dy",
        "outputId": "61f09da9-c1ec-4c86-e999-00237dc3bba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b8899a6ae86d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy =', accuracy)"
      ],
      "metadata": {
        "id": "RsRA8_Rov1GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='train accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z5Z0KJJTv1K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_img_path=input(\" enter your path :- \")\n",
        "# input_image=cv2.imread(input_img_path)\n",
        "# cv2_imshow(input_image)\n",
        "# input_image_scaled=input_image/255\n",
        "# input_image_reshaped = np.reshape(input_image_scaled, [1,32,32,3])\n",
        "# input_prediction = model.predict(input_image_reshaped)\n",
        "# print(input_prediction)\n",
        "# input_pred_label = np.argmax(input_prediction)\n",
        "# print(input_pred_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "bGul3ohOv1Pf",
        "outputId": "b11f5617-0c13-4ac4-b929-a23a700584f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " enter your path :- /content/train/10009.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "[[9.9933076e-01 7.0783756e-08 2.7976607e-04 9.1286774e-06 4.2008041e-06\n",
            "  1.2660142e-07 2.3958947e-07 1.2771031e-08 3.7525737e-04 6.4300986e-07]]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "input_img_path = input(\"Enter your image path: \")\n",
        "input_image = cv2.imread(input_img_path)\n",
        "input_image_resized = cv2.resize(input_image, (32, 32))\n",
        "cv2_imshow(input_image_resized)\n",
        "input_image_scaled = input_image_resized / 255.0\n",
        "input_image_reshaped = np.reshape(input_image_scaled, (1, 32, 32, 3))  # Reshape to match model input shape\n",
        "\n",
        "# Make prediction\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "print(\"Predicted probabilities:\", input_prediction)\n",
        "\n",
        "# Get predicted label\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "print(\"Predicted label:\", input_pred_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "h4P_sSxr4NDU",
        "outputId": "3ca2e7ad-63ed-44e5-c1bb-e9f3fe0537a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your image path: /content/download.jpeg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted probabilities: [[9.4862765e-01 3.2487600e-03 2.1953266e-03 3.4121212e-04 1.9446529e-03\n",
            "  2.9043133e-05 4.4761899e-05 1.1218787e-04 3.8936093e-02 4.5202551e-03]]\n",
            "Predicted label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dictionary = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
        "\n",
        "labels = [labels_dictionary[i] for i in labels_df['label']]"
      ],
      "metadata": {
        "id": "mYB7cMcb_Rpd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}